data:
  maxlen: 256
  start_idx: 0
  end_idx: 10000
model:
  name: 'transformers'
  maxlen: 256
  embed_dim: 128
  drop_out: 0.25
  nhead: 4
  max_norm: 1
  max_words: 10000
  num_layers: 2
  dim_feedforward: 256
  activation: 'gelu'
optimizer: 'Adam'
scheduler: 
  name: 'steplr'
  patience: 2
  step_size: 5
  gamma: 0.1
lr: 1.0e-3
weight_decay: 5.0e-4
batchsize: 64
epoch: 8
num_worker: 4